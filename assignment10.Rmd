
---
output: 
  html_document:
  pdf_document: default
  word_document: default
title: "Assignment 10: Predictive Modeling - Part 1"
---

***How to do it?***: 

- Open the Rmarkdown file of this assignment ([link](assignment10.Rmd)) in Rstudio. 

- Right under each **question**, insert  a code chunk (you can use the hotkey `Ctrl + Alt + I` to add a code chunk) and code the solution for the question. 

- `Knit` the rmarkdown file (hotkey: `Ctrl + Alt + K`) to export an html.  

-  Publish the html file to your Githiub Page. 

***Submission***: Submit the link on Github of the assignment to Canvas

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


-------

1. Use the `Adult Census Income` dataset.  We will predict the income (whether or not it is more than 50k or not) of an adult. Import the dataset.  Partition the data into 80% training and 20% testing.  
```{r}

library(gganimate)
library(ggplot2)
library(tidyverse)
library(knitr)
library(tidyverse)
setwd("C:/Users/student/Downloads")
df =  read_csv('adult_census.csv')
df <- df %>% rename(target=income)
df <- df %>% select(-workclass, -occupation, -native.country, -hours.per.week, -capital.loss, -education.num, -fnlwgt)
df = drop_na(df)
df <- df %>% 
  mutate(target = as.factor(target),
         marital.status = as.factor(marital.status),
         education = as.factor(education),
         race = as.factor(race),
         relationship = as.factor(relationship),
         sex = as.factor(sex)
         )

#install.packages("caret")
library(caret)
set.seed(100)
splitIndex <- createDataPartition(df$target, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]

head(df)
```

2. Practice Decision Tree.  Do the follows:

  - Use `rpart` package, create a decision tree with maximum depth of 3. 
```{r}
library(rpart) #load the rpart package
# Create a tree
tree_model <- rpart(target ~ ., data = df_train,
                 control = rpart.control(maxdepth = 3))
head(df)

```
  
  - Calculate the accuracy of the model on the testing data. Notice that the positive outcome here is not `1` but `>50K` or `<50K`. 
```{r}

#predict on testing data
pred <- predict(tree_model, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = factor(df_test$target), positive = ">50K")
cm$overall[1]


```
  
  - Plot the tree
```{r}
#install.packages("rattle")
library(rattle)
fancyRpartPlot(tree_model)



```
  
  - Plot the variable importance by the tree
```{r}
tree_model$variable.importance
```


```{r}
barplot(tree_model$variable.importance)

```
  
3. Create 3 more trees and compare the testing accuracy of these trees, which tree give the highest testing accuracy.
```{r}
setwd("C:/Users/student/Downloads")
df =  read_csv('adult_census.csv')
df <- df %>% rename(target=income)
df <- df %>% select(-workclass, -occupation, -native.country, -hours.per.week, -education.num, -relationship)
df = drop_na(df)
df <- df %>% 
  mutate(target = as.factor(target),
         marital.status = as.factor(marital.status),
         education = as.factor(education),
         race = as.factor(race),
         sex = as.factor(sex)
         )

#install.packages("caret")
library(caret)
set.seed(100)
splitIndex <- createDataPartition(df$target, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]


library(rpart) #load the rpart package
# Create a tree
tree_model <- rpart(target ~ ., data = df_train,
                 control = rpart.control(maxdepth = 3))


#predict on testing data
pred <- predict(tree_model, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = factor(df_test$target), positive = ">50K")
cm$overall[1]


```
```{r}
setwd("C:/Users/student/Downloads")
df =  read_csv('adult_census.csv')
df <- df %>% rename(target=income)
df <- df %>% select(-workclass, -occupation, -native.country, -hours.per.week, -education.num, -relationship, -marital.status)
df = drop_na(df)
df <- df %>% 
  mutate(target = as.factor(target),
         education = as.factor(education),
         race = as.factor(race),
         sex = as.factor(sex)
         )

#install.packages("caret")
library(caret)
set.seed(100)
splitIndex <- createDataPartition(df$target, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]


library(rpart) #load the rpart package
# Create a tree
tree_model <- rpart(target ~ ., data = df_train,
                 control = rpart.control(maxdepth = 3))


#predict on testing data
pred <- predict(tree_model, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = factor(df_test$target), positive = ">50K")
cm$overall[1]



```
```{r}
setwd("C:/Users/student/Downloads")
df =  read_csv('adult_census.csv')
df <- df %>% rename(target=income)
df <- df %>% select(-workclass, -occupation, -native.country, -hours.per.week, -education.num, -relationship, -marital.status, -capital.gain)
df = drop_na(df)
df <- df %>% 
  mutate(target = as.factor(target),
         education = as.factor(education),
         race = as.factor(race),
         sex = as.factor(sex)
         )

#install.packages("caret")
library(caret)
set.seed(100)
splitIndex <- createDataPartition(df$target, p = .80, 
                                  list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]


library(rpart) #load the rpart package
# Create a tree
tree_model <- rpart(target ~ ., data = df_train,
                 control = rpart.control(maxdepth = 3))


#predict on testing data
pred <- predict(tree_model, df_test, type = "class")
#Evaluate the predictions
cm <- confusionMatrix(data = pred, reference = factor(df_test$target), positive = ">50K")
cm$overall[1]


```

4. Practice Random Forest.  Do the follows: 

  - Use `randomForest` package, create a random forest of 1000 trees. 
```{r}
setwd("C:/Users/student/Downloads")
df =  read_csv('adult_census.csv')
df <- df %>% rename(target=income)
df <- df %>% select(-workclass, -occupation, -native.country, -hours.per.week, -education.num, -capital.gain)
df = drop_na(df)
df <- df %>% 
  mutate(target = as.factor(target),
         marital.status = as.factor(marital.status),
         education = as.factor(education),
         race = as.factor(race),
         relationship = as.factor(relationship),
         sex = as.factor(sex)
         )
library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 1000)
pred <- predict(forest_model, df_test, type = "class")



```
  
  - Calculate the accuracy of the model on the testing data. 
```{r}

cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]


```
  
  - Plot the variable importance by the forest
```{r}

importance(forest_model)


```

5. Create 3 more forests and compare the testing accuracy of these forests, which forest give the highest testing accuracy.
```{r}
setwd("C:/Users/student/Downloads")
df =  read_csv('adult_census.csv')
df <- df %>% rename(target=income)
df <- df %>% select(-workclass, -occupation, -native.country, -hours.per.week, -education.num, -relationship, -marital.status)
df = drop_na(df)
df <- df %>% 
  mutate(target = as.factor(target),
         education = as.factor(education),
         race = as.factor(race),
         sex = as.factor(sex)
         )
library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 1000)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]

```
```{r}
setwd("C:/Users/student/Downloads")
df =  read_csv('adult_census.csv')
df <- df %>% rename(target=income)
df <- df %>% select(-workclass, -occupation, -native.country, -hours.per.week, -education.num, -relationship)
df = drop_na(df)
df <- df %>% 
  mutate(target = as.factor(target),
         education = as.factor(education),
         race = as.factor(race),
         sex = as.factor(sex)
         )
library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 1000)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]


```
```{r}
setwd("C:/Users/student/Downloads")
df =  read_csv('adult_census.csv')
df <- df %>% rename(target=income)
df <- df %>% select(-workclass, -occupation, -native.country, -hours.per.week, -education.num)
df = drop_na(df)
df <- df %>% 
  mutate(target = as.factor(target),
         education = as.factor(education),
         race = as.factor(race),
         sex = as.factor(sex)
         )
library(randomForest)
forest_model = randomForest(target ~ ., data=df_train, ntree = 1000)
pred <- predict(forest_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
cm$overall[1]


```

6. What is the best model (in term of testing accuracy) among all models (including trees and forests) you have trained?
```{r}

# The best model overall was the first decision tree, even though random forests are usually more advanced and accurate. This is probably because I used more variables in total in this first decision tree than any other models, so this is why it was probably most accurate.


```

